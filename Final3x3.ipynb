{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c167a59-0830-4b60-9691-f6604590531a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39fd6640-b5cd-481b-b5ff-54a3e59f7e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data took 0.54 seconds\n",
      "Class distribution: Counter({1: 500192, 0: 499808})\n",
      "X_train shape: (800000, 9)\n",
      "X_test shape: (200000, 9)\n",
      "Training set class distribution: Counter({1: 400154, 0: 399846})\n",
      "Test set class distribution: Counter({1: 100038, 0: 99962})\n",
      "Balanced training set class distribution: Counter({0: 399846, 1: 399846})\n",
      "Extended Symbol Names: ['X', 'O', 'Empty', 'StartingPlayer0', 'StartingPlayer1', 'Center', 'Edge', 'Corner']\n",
      "Preparing training graphs...\n",
      "Training graphs created.\n",
      "Preparing test graphs...\n",
      "Test graphs created.\n",
      "y_train shape: (799692,) dtype: int32\n",
      "y_test shape: (200000,) dtype: int32\n",
      "Initialization of sparse structure.\n",
      "Epoch#1 -- Accuracy train: 0.9983 -- Accuracy test: 0.9984\n",
      "Epoch#2 -- Accuracy train: 1.0000 -- Accuracy test: 1.0000\n",
      "Epoch#3 -- Accuracy train: 1.0000 -- Accuracy test: 1.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 270\u001b[0m\n\u001b[1;32m    268\u001b[0m start_training \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[0;32m--> 270\u001b[0m     \u001b[43mtm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraphs_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincremental\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     train_predictions \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mpredict(graphs_train)\n\u001b[1;32m    272\u001b[0m     train_accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(y_train \u001b[38;5;241m==\u001b[39m train_predictions)\n",
      "File \u001b[0;32m~/GraphTsetlinMachine/GraphTsetlinMachine/tm.py:545\u001b[0m, in \u001b[0;36mMultiClassGraphTsetlinMachine.fit\u001b[0;34m(self, graphs, Y, epochs, incremental)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumber_of_outputs):\n\u001b[1;32m    543\u001b[0m \tencoded_Y[:,i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(Y \u001b[38;5;241m==\u001b[39m i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m--> 545\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoded_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincremental\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mincremental\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GraphTsetlinMachine/GraphTsetlinMachine/tm.py:372\u001b[0m, in \u001b[0;36mCommonTsetlinMachine._fit\u001b[0;34m(self, graphs, encoded_Y, epochs, incremental)\u001b[0m\n\u001b[1;32m    368\u001b[0m cuda\u001b[38;5;241m.\u001b[39mmemcpy_htod(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_sum_gpu, class_sum)\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m### Inference \u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m current_clause_node_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mgraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraphs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumber_of_graph_nodes\u001b[49m\u001b[43m[\u001b[49m\u001b[43me\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraphs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43me\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraphs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgraphs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43me\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m\t\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_clause_node_output_train_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m\t\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_clause_node_output_train_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m\t\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumber_of_graph_node_edges_train_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m\t\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_train_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m\t\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclause_X_int_train_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m\t\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclause_X_train_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\t\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoded_X_train_gpu\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m### Learning\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# Select one true node per clause\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_clause_node\u001b[38;5;241m.\u001b[39mprepared_call(\n\u001b[1;32m    390\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid,\n\u001b[1;32m    391\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclause_node_gpu\n\u001b[1;32m    396\u001b[0m )\n",
      "File \u001b[0;32m~/GraphTsetlinMachine/GraphTsetlinMachine/tm.py:324\u001b[0m, in \u001b[0;36mCommonTsetlinMachine._evaluate\u001b[0;34m(self, graphs, number_of_graph_nodes, node_index, edge_index, current_clause_node_output, next_clause_node_output, number_of_graph_node_edges, edge, clause_X_int, clause_X, encoded_X)\u001b[0m\n\u001b[1;32m    321\u001b[0m cuda\u001b[38;5;241m.\u001b[39mContext\u001b[38;5;241m.\u001b[39msynchronize()\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# Encode messages bitwise\u001b[39;00m\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_messages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepared_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m\t\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m\t\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mnumber_of_graph_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mclause_X_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m\t\u001b[49m\u001b[43mclause_X\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m cuda\u001b[38;5;241m.\u001b[39mContext\u001b[38;5;241m.\u001b[39msynchronize()\n\u001b[1;32m    333\u001b[0m \u001b[38;5;66;03m# Calculate next round of messages\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pycuda/driver.py:573\u001b[0m, in \u001b[0;36m_add_functionality.<locals>.function_prepared_call\u001b[0;34m(func, grid, block, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m texref \u001b[38;5;129;01min\u001b[39;00m func\u001b[38;5;241m.\u001b[39mtexrefs:\n\u001b[1;32m    571\u001b[0m     func\u001b[38;5;241m.\u001b[39mparam_set_texref(texref)\n\u001b[0;32m--> 573\u001b[0m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_buf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from time import time\n",
    "from collections import Counter\n",
    "from GraphTsetlinMachine.graphs import Graphs\n",
    "from GraphTsetlinMachine.tm import MultiClassGraphTsetlinMachine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# Define default arguments using a class\n",
    "class Args:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.epochs = 50             \n",
    "        self.number_of_clauses = 2000  \n",
    "        self.T = 1500                 \n",
    "        self.s = 1.2                \n",
    "        self.depth = 3               \n",
    "        self.hypervector_size = 1024\n",
    "        self.hypervector_bits = 2\n",
    "        self.message_size = 1024\n",
    "        self.message_bits = 2\n",
    "        self.double_hashing = True\n",
    "        self.max_included_literals = 32\n",
    "        # Update any kwargs passed\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Load data\n",
    "start_time = time()\n",
    "try:\n",
    "    data = pd.read_csv('datasett/3x3.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'datasett/3x3.csv' not found. Please ensure the dataset is in the correct directory.\")\n",
    "    exit(-1)\n",
    "end_time = time()\n",
    "print(f\"Loading data took {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "board_size = 3\n",
    "# Define cell columns matching your dataset\n",
    "cell_columns = [f'cell{row}_{col}' for row in range(board_size) for col in range(board_size)]  # ['cell0_0', 'cell0_1', ..., 'cell2_2']\n",
    "\n",
    "# Ensure that 'winner' and 'starting_player' are in the data\n",
    "required_columns = ['winner', 'starting_player'] + cell_columns\n",
    "missing_columns = [col for col in required_columns if col not in data.columns]\n",
    "if missing_columns:\n",
    "    print(f\"Error: Missing columns in the dataset: {missing_columns}\")\n",
    "    exit(-1)\n",
    "\n",
    "# Extract the board states and labels\n",
    "X_df = data[cell_columns]\n",
    "y = data['winner'].values.astype(int)\n",
    "starting_player = data['starting_player'].values.astype(int)\n",
    "\n",
    "# Handle missing values\n",
    "if X_df.isnull().values.any():\n",
    "    print(\"Warning: Missing values detected in X_df. Filling missing values with 0.\")\n",
    "    X_df = X_df.fillna(0)\n",
    "\n",
    "# Map labels to 0 and 1 (if necessary)\n",
    "unique_labels = np.unique(y)\n",
    "if not set(unique_labels).issubset({0, 1}):\n",
    "    label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    y = np.array([label_mapping[label] for label in y])\n",
    "    print(\"Labels mapped to:\", label_mapping)\n",
    "\n",
    "# Check class distribution\n",
    "label_counts = Counter(y)\n",
    "print(f\"Class distribution: {label_counts}\")\n",
    "\n",
    "# Define test size as 20% of the data\n",
    "test_size_dynamic = 0.2\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "try:\n",
    "    X_train_df, X_test_df, y_train, y_test, sp_train, sp_test = train_test_split(\n",
    "        X_df, y, starting_player, test_size=test_size_dynamic, random_state=seed_value, stratify=y\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"Error during train-test split: {e}\")\n",
    "    exit(-1)\n",
    "\n",
    "print(f\"X_train shape: {X_train_df.shape}\")\n",
    "print(f\"X_test shape: {X_test_df.shape}\")\n",
    "\n",
    "# Convert y_train and y_test to pandas Series with matching indices\n",
    "y_train = pd.Series(y_train, index=X_train_df.index)\n",
    "y_test = pd.Series(y_test, index=X_test_df.index)\n",
    "sp_train = pd.Series(sp_train, index=X_train_df.index)\n",
    "sp_test = pd.Series(sp_test, index=X_test_df.index)\n",
    "\n",
    "# Check class distribution in training and test sets\n",
    "train_label_counts = Counter(y_train)\n",
    "test_label_counts = Counter(y_test)\n",
    "print(\"Training set class distribution:\", train_label_counts)\n",
    "print(\"Test set class distribution:\", test_label_counts)\n",
    "\n",
    "# Balance the training set if necessary\n",
    "min_class_size = min(train_label_counts.values())\n",
    "if min_class_size < max(train_label_counts.values()):\n",
    "    class_indices = {}\n",
    "    classes = np.unique(y_train)\n",
    "    for cls in classes:\n",
    "        cls_indices = y_train[y_train == cls].index\n",
    "        class_indices[cls] = cls_indices\n",
    "\n",
    "    # Sample min_class_size from each class\n",
    "    selected_indices = []\n",
    "    for cls, indices in class_indices.items():\n",
    "        selected_cls_indices = np.random.choice(indices, min_class_size, replace=False)\n",
    "        selected_indices.extend(selected_cls_indices)\n",
    "\n",
    "    np.random.shuffle(selected_indices)\n",
    "\n",
    "    X_train_df = X_train_df.loc[selected_indices].reset_index(drop=True)\n",
    "    y_train = y_train.loc[selected_indices].reset_index(drop=True)\n",
    "    sp_train = sp_train.loc[selected_indices].reset_index(drop=True)\n",
    "\n",
    "    # Verify balanced class distribution\n",
    "    train_label_counts = Counter(y_train)\n",
    "    print(\"Balanced training set class distribution:\", train_label_counts)\n",
    "else:\n",
    "    print(\"Training set is already balanced.\")\n",
    "\n",
    "# Ensure X_train_df and y_train have the same number of samples\n",
    "assert X_train_df.shape[0] == y_train.shape[0], \"Mismatch between X_train_df and y_train after balancing.\"\n",
    "\n",
    "# Map cell values to symbols for GTM\n",
    "value_to_symbol = {1: 'X', -1: 'O', 0: 'Empty'}\n",
    "\n",
    "# Define symbols including additional node properties\n",
    "symbol_names = ['X', 'O', 'Empty', 'StartingPlayer0', 'StartingPlayer1', 'Center', 'Edge', 'Corner']\n",
    "\n",
    "print(\"Extended Symbol Names:\", symbol_names)\n",
    "\n",
    "# Helper function to map (q, r) to node_id\n",
    "def position_to_edge_id(pos, board_size):\n",
    "    return pos[0] * board_size + pos[1]\n",
    "\n",
    "# Prepare the graph data\n",
    "def prepare_graph_data(X_df, sp_series):\n",
    "    num_graphs = X_df.shape[0]\n",
    "    graphs = Graphs(\n",
    "        number_of_graphs=num_graphs,\n",
    "        symbols=symbol_names,\n",
    "        hypervector_size=args.hypervector_size,\n",
    "        hypervector_bits=args.hypervector_bits,\n",
    "        double_hashing=args.double_hashing,\n",
    "    )\n",
    "\n",
    "    # Define nodes as (q, r) coordinates\n",
    "    nodes = [(q, r) for q in range(board_size) for r in range(board_size)]\n",
    "    node_id_map = {(q, r): idx for idx, (q, r) in enumerate(nodes)}\n",
    "\n",
    "    # Define neighbor directions (8-connected grid)\n",
    "    directions = [\n",
    "        (0, 1),    # Up\n",
    "        (1, 1),    # Up-Right\n",
    "        (1, 0),    # Right\n",
    "        (1, -1),   # Down-Right\n",
    "        (0, -1),   # Down\n",
    "        (-1, -1),  # Down-Left\n",
    "        (-1, 0),   # Left\n",
    "        (-1, 1),   # Up-Left\n",
    "    ]\n",
    "\n",
    "    # Prepare edges and count outgoing edges per node\n",
    "    edges = []\n",
    "    n_edges_list = [0 for _ in range(board_size**2)]  # Initialize list to count outgoing edges per node\n",
    "\n",
    "    for q, r in nodes:\n",
    "        for dq, dr in directions:\n",
    "            neighbor_q = q + dq\n",
    "            neighbor_r = r + dr\n",
    "            if 0 <= neighbor_q < board_size and 0 <= neighbor_r < board_size:\n",
    "                node_id = node_id_map[(q, r)]\n",
    "                neighbor_id = node_id_map[(neighbor_q, neighbor_r)]\n",
    "                if node_id < neighbor_id:  # Ensure each undirected edge is added only once\n",
    "                    edges.append((node_id, neighbor_id))\n",
    "                    n_edges_list[node_id] += 1  # Increment outgoing edge count\n",
    "\n",
    "    # Set number of nodes and prepare configurations\n",
    "    for graph_id in range(num_graphs):\n",
    "        graphs.set_number_of_graph_nodes(graph_id=graph_id, number_of_graph_nodes=board_size**2)\n",
    "    graphs.prepare_node_configuration()\n",
    "\n",
    "    # Add nodes with their number of outgoing edges\n",
    "    for graph_id in range(num_graphs):\n",
    "        for k in range(board_size**2):\n",
    "            graphs.add_graph_node(graph_id, k, n_edges_list[k])\n",
    "    graphs.prepare_edge_configuration()\n",
    "\n",
    "    # Add node properties and edges\n",
    "    for graph_id in range(num_graphs):\n",
    "        row = X_df.iloc[graph_id]\n",
    "        board_state = row.values.astype(int)\n",
    "        board_state_symbols = [value_to_symbol.get(cell_value, 'Empty') for cell_value in board_state]\n",
    "        sp = sp_series.iloc[graph_id]\n",
    "\n",
    "        for idx, (q, r) in enumerate(nodes):\n",
    "            sym = board_state_symbols[idx]\n",
    "            graphs.add_graph_node_property(graph_id, idx, sym)\n",
    "\n",
    "            # Add starting player as node property\n",
    "            graphs.add_graph_node_property(graph_id, idx, f'StartingPlayer{sp}')\n",
    "\n",
    "            # Add position type (Center, Edge, Corner)\n",
    "            if (q == 1 and r == 1):\n",
    "                graphs.add_graph_node_property(graph_id, idx, 'Center')\n",
    "            elif (q == 0 or q == 2) and (r == 0 or r == 2):\n",
    "                graphs.add_graph_node_property(graph_id, idx, 'Corner')\n",
    "            else:\n",
    "                graphs.add_graph_node_property(graph_id, idx, 'Edge')\n",
    "\n",
    "        # Add edges\n",
    "        for node_id, neighbor_id in edges:\n",
    "            graphs.add_graph_node_edge(graph_id, node_id, neighbor_id, edge_type_name=0)\n",
    "\n",
    "    # Encode the graphs\n",
    "    graphs.encode()\n",
    "    return graphs\n",
    "\n",
    "# Prepare training graphs\n",
    "print(\"Preparing training graphs...\")\n",
    "graphs_train = prepare_graph_data(X_train_df, sp_train)\n",
    "print(\"Training graphs created.\")\n",
    "\n",
    "# Prepare test graphs\n",
    "print(\"Preparing test graphs...\")\n",
    "graphs_test = prepare_graph_data(X_test_df, sp_test)\n",
    "print(\"Test graphs created.\")\n",
    "\n",
    "# Ensure y_train and y_test are numpy arrays of correct type\n",
    "y_train = y_train.values.astype(np.int32).reshape(-1)\n",
    "y_test = y_test.values.astype(np.int32).reshape(-1)\n",
    "\n",
    "# Verify the shapes and data types\n",
    "print(\"y_train shape:\", y_train.shape, \"dtype:\", y_train.dtype)\n",
    "print(\"y_test shape:\", y_test.shape, \"dtype:\", y_test.dtype)\n",
    "\n",
    "# Initialize the Tsetlin Machine with adjusted hyperparameters\n",
    "try:\n",
    "    tm = MultiClassGraphTsetlinMachine(\n",
    "        args.number_of_clauses,\n",
    "        args.T,\n",
    "        args.s,\n",
    "        len(np.unique(y_train)),  # number_of_classes as positional argument\n",
    "        depth=args.depth,\n",
    "        max_included_literals=args.max_included_literals,\n",
    "        message_size=args.message_size,\n",
    "        message_bits=args.message_bits,\n",
    "        grid=(16*13,1,1),   # Adjust based on your GPU setup\n",
    "        block=(128,1,1)\n",
    "    )\n",
    "except TypeError as e:\n",
    "    print(f\"Initialization Error: {e}\")\n",
    "    exit(-1)\n",
    "\n",
    "# Training loop with adjusted hyperparameters\n",
    "start_training = time()\n",
    "for i in range(args.epochs):\n",
    "    tm.fit(graphs_train, y_train, epochs=1, incremental=True)\n",
    "    train_predictions = tm.predict(graphs_train)\n",
    "    train_accuracy = np.mean(y_train == train_predictions)\n",
    "    test_predictions = tm.predict(graphs_test)\n",
    "    test_accuracy = np.mean(y_test == test_predictions)\n",
    "    print(f\"Epoch#{i+1} -- Accuracy train: {train_accuracy:.4f} -- Accuracy test: {test_accuracy:.4f}\")\n",
    "stop_training = time()\n",
    "print(f\"Training Time: {stop_training - start_training:.2f} seconds\")\n",
    "\n",
    "# Evaluation Metrics\n",
    "print(\"\\nClassification Report on Test Set:\")\n",
    "print(classification_report(y_test, test_predictions, digits=4))\n",
    "\n",
    "print(\"Confusion Matrix on Test Set:\")\n",
    "print(confusion_matrix(y_test, test_predictions))\n",
    "\n",
    "# Check predictions to see if the model is predicting all classes\n",
    "print(\"\\nChecking predictions on training and test sets...\")\n",
    "unique_train_preds, counts_train_preds = np.unique(train_predictions, return_counts=True)\n",
    "print(\"Unique predictions on training set:\", unique_train_preds)\n",
    "print(\"Training set predictions distribution:\", dict(zip(unique_train_preds, counts_train_preds)))\n",
    "\n",
    "unique_test_preds, counts_test_preds = np.unique(test_predictions, return_counts=True)\n",
    "print(\"Unique predictions on test set:\", unique_test_preds)\n",
    "print(\"Test set predictions distribution:\", dict(zip(unique_test_preds, counts_test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0737e9f-fbfc-4b45-ba8f-057b08638a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
